# -*- coding: utf-8 -*-
"""NLTK Course - Word Tokenization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12xV_fBtKHxnh3WrqCcJrRcwDmlgrK-ei
"""

import nltk
nltk.download('punkt')

from nltk.tokenize import word_tokenize
string = "Hi! This is a simple sentence, and it can't be simpler!!"
print(word_tokenize(string))

from nltk.tokenize import WordPunctTokenizer
tokenizer = WordPunctTokenizer()
tokenizer.tokenize("Can't is a contraction.")

from nltk.tokenize import regexp_tokenize, wordpunct_tokenize

string = "Hi! This is a simple sentence, and it can't be simpler!! like 2 by 2"

#regexp_tokenize(string, "[\w']+")
# # Split the words
#regexp_tokenize(string, pattern='\w+')
# # Split the digits
#regexp_tokenize(string, pattern='\d+')
# # Split the punctuations and words
wordpunct_tokenize(string)